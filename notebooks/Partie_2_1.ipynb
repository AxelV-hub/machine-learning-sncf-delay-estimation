{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Prédiction du temps de retard juste après le départ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette approche du problème, on cherche à prévoir le temps de retard prévu pour les trains qu’on sait être en retard au départ. Cette prédiction peut être utile à plusieurs égards :\n",
    "- Pour les utilisateurs d’abord, à qui on peut prédire le retard auquel ils peuvent s'attendre à l'arrivée lorsqu’ils apprennent que leur train est en retard au départ. La SNCF cherche d’ailleurs déjà à partager cette information à ses clients à travers l’application SNCF ou sur les différents affichages en gare et dans les trains. \n",
    "- Cela permet aussi à la SNCF de prendre des mesures efficaces s'il y a des correspondances et de donner une première information aussi précise que possible à ses clients. \n",
    "\n",
    "Un train en retard au départ n’est en général plus prioritaire et ne pourra être mis en circulation qu’au prochain créneau libre. Il se peut qu’il soit tout de même priorisé si son retard perturbe de nombreux autres trajets (dans le cas de correspondances notamment). Deux cas de figure sont donc envisageables lorsqu’un train est en retard au départ : \n",
    "- Le train peut encore être priorisé pour compenser son retard et il a de chances d’arriver à l’heure\n",
    "- Le train ne peut plus être priorisé et on est sûr qu’il sera en retard à l’arrivée\n",
    "\n",
    "Dans le premier cas, nous chercherons à prédire retard_moyen_tous_trains_arrivee, dans le deuxième cas nous chercherons à prédire retard_moyen_arrivee (le train ne peut plus arriver à l’heure, il fait déjà partie de la catégorie des trains en retard à l’arrivée). La démarche suivie ci-après est exactement la même dans les deux cas à cette exception près. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant propos : \n",
    "\n",
    "Une méthode de discrétisation des retards a été expérimentée sans grand succès. Les catégories utilisées étaient les suivantes : 0-10, 10-20, 20-30, 30-45, 45-60, >60. Malheureusement, l'accuracy obtenue était de 60% au mieux avec les différents modèles testés, ce qui n'était pas convaincant. Les modèles de regression ont donc été retenus pour la suite du travail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cellule d'importation\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choix du cas considéré. Assignez 'retard_moyen_tous_trains arrivee' à column pour le cas 1 (train priorisable), 'retard_moyen_arrivee' sinon (train non priorisable).\n",
    "\n",
    "column = 'retard_moyen_arrivee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous reprenons les mêmes hypothèses et faisons les mêmes traintements que dans la partie 2.1 pour commencer. Nous ajoutons en plus des données déjà utilisées précédemment les données suivantes : \n",
    "- Le nombre de trains en retard au départ dans le mois d’intérêt\n",
    "- Le retard moyen des trains en retard au départ dans le mois d’intérêt.\n",
    "\n",
    "Pour avoir ces données à n'importe quel moment du mois, il faudrait un modèle qui prédit le nombre de retards au départ et leurs moyenne à partir du nombre de retards et leur moyenne jusqu’à la date considérée. Ce problème n’a pas été traité ici mais nous partons du principe qu’il existe et qu’il est efficace. \n",
    "\n",
    "\n",
    "En plus de ce qui a été fait dans la partie 2.1, nous effectuons également un one-hot-encoding sur la présence ou non de commentaires concernant les retards le mois d’avant. En effet, ces commentaires indiquent des causes extraordinaires ayant influencé les retards. Ceci pourrait influencer les retards du mois d’après. \n",
    "On ajoute également les pourcentages de chacune des causes des 4 mois précédant le mois d’intérêt ainsi que la moyenne sur tous les mois précédents. Certaines causes impliquent des mesures chronophages qui peuvent influer sur les retards des mois futurs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('../dataset/regularite-mensuelle-tgv-aqst.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#On ajoute un colonne année \n",
    "annee = []\n",
    "mois = []\n",
    "for i in df['date'].values :\n",
    "    annee.append(int(i[:4]))\n",
    "    mois.append(int(i[5:]))\n",
    "\n",
    "df['annee'] = annee\n",
    "df['mois'] = mois\n",
    "\n",
    "#On supprime la colonne date\n",
    "\n",
    "df = df.drop(['date'], axis = 1)\n",
    "\n",
    "\n",
    "#On transforme la colonne commentaire, si un commentaire est présent, on met un 1, sinon un 0. Les commentaires signifie en général des éléments extraordinaire qui peuvent augmenter les retards.\n",
    "def comm(com):\n",
    "    if pd.isna(com): \n",
    "        return 0\n",
    "    else :\n",
    "        return 1\n",
    "    \n",
    "#On fait la transformation\n",
    "df.loc[:, 'commentaires_retard_arrivee'] = df['commentaires_retard_arrivee'].apply(comm)\n",
    "\n",
    "\n",
    "#On ajoute une colonne \"retards_moy_arrivee_trajet_passés\"\n",
    "\n",
    "def moyenne_donnee_passee(df, column):\n",
    "    df[column +\"_passe\"] = 0.0\n",
    "    for i,row in df.iterrows():\n",
    "        df.loc[i, column + \"_passe\" ] = df[(df['annee'] <= row['annee']) & (df['gare_depart']== row['gare_depart']) & (df['gare_arrivee']== row['gare_arrivee']) & (df['mois'] <= row['mois'])][column].mean()\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#On crée la fonction qui permet d'ajouter les valeurs des retards des mois précédents\n",
    "\n",
    "def add_data_previous_months(df, n_months, column):\n",
    "    past_month_cols = [f\"{column}_mois_n-{i}\" for i in range(1, n_months+1)]\n",
    "    for col in past_month_cols:\n",
    "        df[col] = 0.0\n",
    "    for i,row in df.iterrows():\n",
    "        annee, mois = row[\"annee\"], row[\"mois\"]\n",
    "        gare_depart, gare_arrivee = row[\"gare_depart\"], row[\"gare_arrivee\"]\n",
    "        for j, col_name in enumerate(past_month_cols):\n",
    "            n_mois_a_soustraire = j+1\n",
    "            date_mois_prec = (annee, mois-n_mois_a_soustraire) if mois>=n_mois_a_soustraire+1 else ((annee-1, 12+mois-n_mois_a_soustraire) if annee>=2019 else (annee, mois))\n",
    "            series = df.loc[(df.gare_depart == gare_depart) & (df.gare_arrivee == gare_arrivee) & (df.annee == date_mois_prec[0]) & (df.mois == date_mois_prec[1]), column]\n",
    "            \n",
    "            if not series.empty:\n",
    "                value = series.values[0]\n",
    "                \n",
    "                df.loc[i, col_name] = value\n",
    "            else:\n",
    "                \n",
    "                df.loc[i, col_name] = row[column + \"_passe\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Méthode de Tuckey pour les outliers\n",
    "\n",
    "def smooth_outliers(val, outlier_step, Q1, Q3):\n",
    "    if val < Q1-outlier_step:\n",
    "        val = Q1-outlier_step\n",
    "    elif val > Q3+outlier_step:\n",
    "        val = Q3+outlier_step\n",
    "    return val\n",
    "\n",
    "def clean_outliers(df, outlier_cols):\n",
    "    # df = input_df.copy(deep=True)\n",
    "    for col_name in outlier_cols:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col_name], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col_name],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        df[col_name] = df[col_name].apply(lambda x: smooth_outliers(x, outlier_step, Q1, Q3))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gestion des outliers\n",
    "outlier_cols = [\"duree_moyenne\", \"nb_train_prevu\", column]\n",
    "df = clean_outliers(df, outlier_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajout des moyennes des mois passés\n",
    "\n",
    "\n",
    "df = moyenne_donnee_passee(df, column )\n",
    "df = moyenne_donnee_passee(df, \"prct_cause_externe\" )\n",
    "df = moyenne_donnee_passee(df, \"prct_cause_infra\" )\n",
    "df = moyenne_donnee_passee(df, \"prct_cause_gestion_trafic\" )\n",
    "df = moyenne_donnee_passee(df, \"prct_cause_materiel_roulant\" )\n",
    "df = moyenne_donnee_passee(df, \"prct_cause_gestion_gare\" )\n",
    "df = moyenne_donnee_passee(df, \"prct_cause_prise_en_charge_voyageurs\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ajoute les données des 4 mois précédents et on affiche le dataframe pour les retards à l'arrivée et les pourcentages de causes.\n",
    "\n",
    "df = add_data_previous_months(df,4 ,column )\n",
    "df = add_data_previous_months(df,4 , \"prct_cause_externe\" )\n",
    "df = add_data_previous_months(df,4 , \"prct_cause_infra\" )\n",
    "df = add_data_previous_months(df,4 , \"prct_cause_gestion_trafic\" )\n",
    "df = add_data_previous_months(df,4 , \"prct_cause_materiel_roulant\" )\n",
    "df = add_data_previous_months(df,4 , \"prct_cause_gestion_gare\" )\n",
    "df = add_data_previous_months(df,4 , \"prct_cause_prise_en_charge_voyageurs\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On enlève les données des quatre premiers mois du dataset où les valeurs des mois précédents n'existe pas. Ces lignes pourraient fausser la donnée.\n",
    "\n",
    "df = df.drop(df[(df['mois'] == 1) & (df['annee'] == 2018)].index)\n",
    "df = df.drop(df[(df['mois'] == 2) & (df['annee'] == 2018)].index)\n",
    "df = df.drop(df[(df['mois'] == 3) & (df['annee'] == 2018)].index)\n",
    "df = df.drop(df[(df['mois'] == 4) & (df['annee'] == 2018)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observons les correlations entre les features et le donnée que nous cherchons à prédire.\n",
    "\n",
    "\n",
    "data_f = df[['annee', 'mois','service', 'gare_depart', 'gare_arrivee', 'duree_moyenne', 'nb_train_prevu','nb_train_depart_retard', \n",
    "            'retard_moyen_depart', column +'_mois_n-1', column +'_mois_n-2', column +'_mois_n-3', column +'_mois_n-4',\n",
    "             'commentaires_retard_arrivee', column +'', column +\"_passe\",\n",
    "                'prct_cause_externe_passe','prct_cause_externe_mois_n-1', 'prct_cause_externe_mois_n-2', 'prct_cause_externe_mois_n-3', 'prct_cause_externe_mois_n-4',\n",
    "                'prct_cause_infra_passe','prct_cause_infra_mois_n-1', 'prct_cause_infra_mois_n-2', 'prct_cause_infra_mois_n-3', 'prct_cause_infra_mois_n-4',\n",
    "                'prct_cause_gestion_trafic_passe','prct_cause_gestion_trafic_mois_n-1', 'prct_cause_gestion_trafic_mois_n-2', 'prct_cause_gestion_trafic_mois_n-3', 'prct_cause_gestion_trafic_mois_n-4',\n",
    "                'prct_cause_materiel_roulant_passe','prct_cause_materiel_roulant_mois_n-1', 'prct_cause_materiel_roulant_mois_n-2', 'prct_cause_materiel_roulant_mois_n-3', 'prct_cause_materiel_roulant_mois_n-4',\n",
    "                 'prct_cause_gestion_gare_passe','prct_cause_gestion_gare_mois_n-1', 'prct_cause_gestion_gare_mois_n-2', 'prct_cause_gestion_gare_mois_n-3', 'prct_cause_gestion_gare_mois_n-4',\n",
    "                  'prct_cause_prise_en_charge_voyageurs_passe','prct_cause_prise_en_charge_voyageurs_mois_n-1', 'prct_cause_prise_en_charge_voyageurs_mois_n-2', 'prct_cause_prise_en_charge_voyageurs_mois_n-3', 'prct_cause_prise_en_charge_voyageurs_mois_n-4']]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(data_f.corr()[[column]].sort_values(by=column, ascending=False), vmin=-1, vmax=1, annot=True, cmap='coolwarm')\n",
    "heatmap.set_title('Features Correlating with {}'.format(column), fontdict={'fontsize':18}, pad=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a réussi à obtenir quelques niveaux de corrélation intéressants et certaines valeurs confirment nos hypothèses. Etant donne que ces pourcentages sont liés (leur somme vaut 1), on peut en déduire que les causes externes ont un fort impact sur les retards alors que la gestion gare et la gestion trafic beaucoup moins. Lorsque ces dernières causes ont un pourcentage élevé, les retards sont plus faibles (corrélation négative). On a également l'impression que les mêmes lignes sont souvent touchées par les mêmes causes car un ligne qui a eu dans le passé des gros pourcentage de causes externes à de fortes chances d'avoir de gros retards dans le futur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#On sépare X et y\n",
    "\n",
    "def transfo_colonnes(a, column):\n",
    "\n",
    "     \n",
    "\n",
    "     X = a[['annee', 'mois','service', 'gare_depart', 'gare_arrivee', 'duree_moyenne', 'nb_train_prevu','nb_train_depart_retard', \n",
    "            'retard_moyen_depart', column +'_mois_n-1', column +'_mois_n-2', column +'_mois_n-3', column +'_mois_n-4',\n",
    "             'commentaires_retard_arrivee', column +\"_passe\",\n",
    "                'prct_cause_externe_passe','prct_cause_externe_mois_n-1', 'prct_cause_externe_mois_n-2', 'prct_cause_externe_mois_n-3', 'prct_cause_externe_mois_n-4',\n",
    "                'prct_cause_infra_passe','prct_cause_infra_mois_n-1', 'prct_cause_infra_mois_n-2', 'prct_cause_infra_mois_n-3', 'prct_cause_infra_mois_n-4',\n",
    "                'prct_cause_gestion_trafic_passe','prct_cause_gestion_trafic_mois_n-1', 'prct_cause_gestion_trafic_mois_n-2', 'prct_cause_gestion_trafic_mois_n-3', 'prct_cause_gestion_trafic_mois_n-4',\n",
    "                'prct_cause_materiel_roulant_passe','prct_cause_materiel_roulant_mois_n-1', 'prct_cause_materiel_roulant_mois_n-2', 'prct_cause_materiel_roulant_mois_n-3', 'prct_cause_materiel_roulant_mois_n-4',\n",
    "                 'prct_cause_gestion_gare_passe','prct_cause_gestion_gare_mois_n-1', 'prct_cause_gestion_gare_mois_n-2', 'prct_cause_gestion_gare_mois_n-3', 'prct_cause_gestion_gare_mois_n-4',\n",
    "                  'prct_cause_prise_en_charge_voyageurs_passe','prct_cause_prise_en_charge_voyageurs_mois_n-1', 'prct_cause_prise_en_charge_voyageurs_mois_n-2', 'prct_cause_prise_en_charge_voyageurs_mois_n-3', 'prct_cause_prise_en_charge_voyageurs_mois_n-4']]\n",
    "     y_train = a[a['annee'] <= 2022][[column ]].values.ravel()\n",
    "     y_test = a[a['annee'] == 2023][[column ]].values.ravel()\n",
    "\n",
    "     #On commence par le one hot encoding des mois, des gares d'arrivée et de départ. \n",
    "     categorical_features = [\"mois\", \"annee\", \"gare_depart\", \"gare_arrivee\", \"service\", \"commentaires_retard_arrivee\"]\n",
    "     #Les valeurs numériques \n",
    "     numeric_features = list(X.drop([\"mois\", \"annee\", \"gare_depart\", \"gare_arrivee\", \"service\", \"commentaires_retard_arrivee\"], axis = 1))\n",
    "\n",
    "\n",
    "     pipeline_traitement_données = ColumnTransformer([\n",
    "          ('std_scaler', StandardScaler(), numeric_features),\n",
    "          ('one-hot', OneHotEncoder(), categorical_features)\n",
    "     ])\n",
    "\n",
    "\n",
    "     #On recrée un dataframe après la transformation pour pouvoir séparer train et test facilement\n",
    "\n",
    "     X_transformed = pipeline_traitement_données.fit_transform(X)\n",
    "\n",
    "     X_train_array = X_transformed.toarray()\n",
    "\n",
    "     column_names_train = pipeline_traitement_données.get_feature_names_out(input_features=X.columns)\n",
    "\n",
    "\n",
    "     # Recreate a DataFrame with column names and values\n",
    "     X_final = pd.DataFrame(X_train_array, columns=column_names_train)\n",
    "\n",
    "     X_test = X_final[X_final['one-hot__annee_2023']== 1 ]\n",
    "     X_train = X_final.drop(X_final[X_final['one-hot__annee_2023']== 1].index)\n",
    "\n",
    "     return [X_train, X_test, y_train, y_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output = transfo_colonnes(df, 'retard_moyen_arrivee') #Ou retard_moyen_tous_trains_arrivee en fonction du cas considéré. \n",
    "\n",
    "X_train = output[0]\n",
    "X_test = output[1]\n",
    "y_train = output[2]\n",
    "y_test = output[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste dans la cellule suivante différents modèles de regression et sortons leurs résultats après cross-validation sur notre training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une liste de modèles de régression à tester\n",
    "models = [\n",
    "    ('Decision Tree', DecisionTreeRegressor()),\n",
    "    ('Random Forest', RandomForestRegressor()),\n",
    "    ('SVR', SVR()),\n",
    "    ('K-Nearest Neighbors', KNeighborsRegressor()),\n",
    "    ('XGbosst', HistGradientBoostingRegressor())\n",
    "]\n",
    "\n",
    "\n",
    "# Créer une matrice pour stocker les erreurs de chaque modèle\n",
    "results = []\n",
    "\n",
    "# Définissez une liste de métriques à utiliser\n",
    "scoring = ['neg_mean_squared_error', 'r2']\n",
    "\n",
    "# Effectuer la validation croisée pour chaque modèle\n",
    "for i, (name, model) in enumerate(models):\n",
    "    # Calculer les erreurs en utilisant la validation croisée\n",
    "    scores = cross_validate(model, X_train, y_train, cv=3, scoring = scoring)\n",
    "    \n",
    "    # Calculer la racine carrée de l'erreur quadratique moyenne (RMSE)\n",
    "    rmse_norm_scores = np.sqrt(-scores['test_neg_mean_squared_error'])\n",
    "    \n",
    "    \n",
    "    # Stocker le nom du modèle et la moyenne des RMSE\n",
    "    results.append((name, rmse_norm_scores.mean(), scores['test_r2'].mean()))\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest à l'air d'être le modèle le plus efficace. Effectuons une grid search pour trouver les meilleurs paramètres. \n",
    "\n",
    "p.s. : Elle est très longue car on entraine de nombreux arbres de décision ce qui prend beaucoup de temps. Elle est donc commentée ici et les meilleurs hyper paramètres sont précisés dans la cellule suivante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # Create the parameter grid based on the results of random search \n",
    "\n",
    "# rf_random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)],\n",
    "#                'max_features': ['auto', 'sqrt'],\n",
    "#                'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "#                'min_samples_split': [2, 5, 10],\n",
    "#                'min_samples_leaf':  [1, 2, 4]}\n",
    "\n",
    "# # Create a based model\n",
    "# rf = RandomForestRegressor()\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = rf_random_grid, \n",
    "#                           cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenez les meilleurs hyperparamètres et le modèle optimal\n",
    "# print(grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fait nos prédictions avec le meilleur modèle qui a les hyper paramètres suivants : 'max_depth': 60,'max_features': 'auto','min_samples_leaf': 4,'min_samples_split': 10,'n_estimators': 1000\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=60, min_samples_leaf=4, min_samples_split=10, n_estimators=1000)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On compare la valeur retournée par notre modèle à la moyenne du retard \n",
    "\n",
    "print(y_test.mean(), np.sqrt(y_test.var()))\n",
    "print((y_test.max(), y_test.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 1\n",
    "\n",
    "On obtient une rmse de 2,4 minutes. Cela parait plutot satisfaisant en particulier étant donné le peu d'informations contractuelles sur les trajets. \n",
    "\n",
    "\n",
    "\n",
    "## Cas 2\n",
    "\n",
    "On obtient une rmse de 9,54 minutes. On remarque que nos prédictions ne sont pas particulièrement meilleures que la variance du dataset de test (13 minutes) et que nous sommes précis à environ un quart de la moyenne des valeurs de retards. Cela n'est pas extrèment convaincant. \n",
    "On peut mitiger cela car la valeur prédite par notre modèle ne sera probablement qu'une bonne première approximation pour la SNCF mais ne sera probablement pas meilleure que celle donnée par des informations en temps réel une fois que le train est en route. Une combinaison des deux approches pourrait probablement fournir les meilleurs résultats.\n",
    "\n",
    "\n",
    "Dans le cas 2, nos prédictions sont moins bonnes que dans le cas 1. Cela vient probablement du fait que les trains qui ne sont pas en retard (retard = 0) viennent lisser les valeurs extrêmes. C'est ce qu'on observe pour Tourcoing_Bordeaux en mars 2023. On a retard_moyen_arrivee = 299.3 et retard_moyen_tous_trains_arrivee = 11.61. S'il y a un seul train en retard mais que celui ci est très en retard, on obtient une valeur énorme pour retard_moyen alors que retard_moyen_tous_trains_arrivee est lissé par tous les autres trains qui ne sont pas en retard. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
